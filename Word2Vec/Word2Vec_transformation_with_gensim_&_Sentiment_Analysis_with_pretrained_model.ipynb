{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_transformation_with_gensim_&_Sentiment_Analysis_with pretrained_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FLALnqrilWjA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Table of Contents \n",
        "\n",
        "1. ** What is Word2Vec**\n",
        "\n",
        "2. **Why word2vec**\n",
        "\n",
        "3. **How does Word2Vec work?**\n",
        "\n",
        "4. **The data**\n",
        "\n",
        "  4.1. About the data\n",
        "\n",
        "  4.2. Clean the data\n",
        "\n",
        " \n",
        "  \n",
        "5 . **Word2Vec with Gensim(The Word2Vec toolkit)**\n",
        "   \n",
        "6 .  **Sentiment Analysis with pretrained model**"
      ]
    },
    {
      "metadata": {
        "id": "nOdEwtMZvIma",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zb_3cABsVT2f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Word2Vec\n",
        "Word2Vec is so far a phenomenal invention in the field of Artificial Intelligence for text processing. \n",
        "This is an unique idea of presenting word into a set numbers ,called vector or in other words vector representation of words.Word2Vec transforms a word into ***d-diemensional*** vector & the dimension can be any integer 300,200 etc that we'll cover gradually in more detail.\n",
        "\n",
        "# 2.  Why word2vec?\n",
        " \n",
        "Primarily One-hot & tf-idf have two major problems;\n",
        "### They produce a very large data table with the possibility of a large number of columns;\n",
        "### One-hot produces a very sparse data table with a very high number of 0s, which might be a problem for training certain machine learning algorithms.\n",
        "<p align=\"center\">\n",
        "<img height=\"170\" width=\"700\" src=\"https://i.imgur.com/mtimFxh.png\"></img>\n",
        "\n",
        "\n",
        "## ***The Word2Vec technique was therefore conceived with two goals in mind***:\n",
        "\n",
        " **Reduce the size of the word encoding space (embedding space);**\n",
        " \n",
        "** Compress in the word representation the most informative description for each word**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1vRlaAP1Wk0_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. How does Word2Vec work?\n",
        "Word2Vec concepts tries to establish a semantic relationship of a word with other words.Here semantic relationship means relating or similar relationship.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"240\" width=\"570\" src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/06062705/Word-Vectors.png\">\n",
        "\n",
        "In the examples above we establish Male-Female relationship.\n",
        "\n",
        "\n",
        "**{ Vector(man) - Vector(woman) = Vector(king) - Vector(queen)}**\n",
        "\n",
        "Verb-tense relationship\n",
        "\n",
        "**walking is present continuous tesnse while walked is past tense. In the same way swimming is to swam**\n",
        "\n",
        "Word2Vec learns this relationships automatically without being programmed from raw-data.\n",
        "\n",
        "\n",
        "\n",
        "**Let's take another example**\n",
        "<p align=\"center\">\n",
        "<img height=\"240\" width=\"570\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=164ebf36362bc0d9&attid=0.1&disp=safe&realattid=f_jk8gxzvc0&zw\">\n",
        "\n",
        "\n",
        "among the given words we expect, delicious,tasty lip-smacking & pudding are similar or closer words on a certain dimension say 50 dimensions and don't expect basketball to be close to any other words. Yes, Word2Vec does the same job for us. It always establishes semantic relationship this way.\n",
        "\n",
        "\n",
        "**Let's dive deep**\n",
        "\n",
        "Word2vec is a neural network that works based on two algorithms namely **CBOW** & **Skip Gram**. We'll discuss each algorithm in this tutorial one by one.\n",
        "\n",
        "### CBOW(Continuous Bag of Words)\n",
        "\n",
        "In word2Vec , we give a word and word2Vec outputs a dense vector.\n",
        "\n",
        "Let's look at the example below to know how CBOW works in Word2Vec\n",
        "  \n",
        "  \n",
        "  **Target word or focus word:**\n",
        "  \n",
        "  A single word in a line of text\n",
        "  \n",
        "  **Context:**\n",
        "  \n",
        "  A set of neighboring words appearing on the sides of focus word.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"380\" width=\"500\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=1651501a2a5b5d53&attid=0.1&disp=safe&realattid=f_jkjv1avu1&zw\">\n",
        "\n",
        "\n",
        "\n",
        "We've a  text of words  where focus word is **dies** & context words are neighboring words like the , sun, everyday, for ,moon.CBOW tries to predict the focus word based on the context(input). V dimensional context is summarized in N-dimensional hidden layer. Here N is the number of numbers we want to represent a word. After end of training we get W(N*V)matrix where N is the dimension of vector ( **Generally no. of neurons in hidden layer** ) & V is dimension of words in a text.\n",
        "Thus for word w1 we get corresponding N-dimensional vector v1 and the process continues for other words too.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"340\" width=\"600\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=1651501a2a5b5d53&attid=0.2&disp=safe&realattid=f_jkjv1aw82&zw\">\n",
        "\n",
        "### SKIP_GRAM\n",
        "\n",
        "Skip-gram is the flip of CBOW.Here we predict the context given a focused word.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"340\" width=\"500\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=1651501a2a5b5d53&attid=0.3&disp=safe&realattid=f_jkjv1awc3&zw\">\n",
        "\n",
        "\n",
        "The focus word is represented on a N-dimensiinal hidden layer and from hidden layer a number of context words are predicted using a number of **softmax(SM)** classifier.\n",
        "\n",
        "**CBOW vs SKIPGRAM**\n",
        "\n",
        "* In skipgram a number of softmax classifiers are required where as in CBOW only one Softmax is required that's why Skipgram is computationally more expensive than CBOW,hence CBOW is faster than skipgram.\n",
        "\n",
        "* CBOW works better frequently occurring words where as skipgram works better in opposite manner.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Wyc_0lfv98xf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.The data\n",
        "\n",
        "   ## 4.1 About the data\n",
        "The analysis seeks to establish transformation of word into vectors on any text. We are not concerned about whether the text data has label or not. The data set supplied consists of  **50000 IMDB reviews**  with review ID on a certain movie  with no labels.We'll use this unlabelled data to train a model. which can be applied on test data.\n",
        "\n",
        "Please visit the site to download the data\n",
        "https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "metadata": {
        "id": "5Qjeipfq-Xvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUO7x4uTqEyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import the data\n",
        "\n",
        "The data was imported from local repository using the command below."
      ]
    },
    {
      "metadata": {
        "id": "y6nYK0Zs-ePR",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "251a1eaf-a185-4b7d-bec5-ff511fa30b85"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0edb8bd8-6bbe-409b-9922-1ba23515c448\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0edb8bd8-6bbe-409b-9922-1ba23515c448\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving unlabeledTrainData.tsv to unlabeledTrainData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sb2PtvNs-ezJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"unlabeledTrainData.tsv\",delimiter=\"\\t\",quoting=3,header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beTir5Bc-e13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cd7d8176-cb49-4a03-b97c-1baf43b42a97"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "fCGqHLWu-e7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re,string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEa71UBQe9X7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4.2. Data Cleaning\n",
        "We've gone through the reviews & detected punctuations in many reviews.The punctuations don't contribute anything to our analysis & moreover they are considered as unique word & distort the meaning of other words.This is why the data needs to be cleaned before we jump into core analysis."
      ]
    },
    {
      "metadata": {
        "id": "UWxkM_PZ-e-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n",
        "  try:\n",
        "    string=re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n",
        "    string=re.sub(r\"[^A-Za-z]\",\" \",string)\n",
        "    words=string.strip().lower().split()\n",
        "    return \" \".join(words)\n",
        "  except:\n",
        "    return \" \"\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRrc9brjJyEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Above we defined a function called **clean_string** & this function we have applied on the raw review column and created a new column(**clean_review**) to save the cleaned reviews."
      ]
    },
    {
      "metadata": {
        "id": "2rZpIB7i-fBK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['clean_review']=df.review.apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrIOSWx3-fFk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "87f4601e-b40f-4223-c3af-83fe64eaa0b7"
      },
      "cell_type": "code",
      "source": [
        "print (\"No.of samples \\n:\",(len(df)))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of samples \n",
            ": 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "      <td>watching time chasers it obvious that it was m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "      <td>i saw this film about years ago and remember i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "      <td>minor spoilers br br in new york joan barnard ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "      <td>i went to see this film with a great deal of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "      <td>yes i agree with everyone on this site this mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review  \\\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...   \n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...   \n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...   \n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...   \n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ...   \n",
              "\n",
              "                                        clean_review  \n",
              "0  watching time chasers it obvious that it was m...  \n",
              "1  i saw this film about years ago and remember i...  \n",
              "2  minor spoilers br br in new york joan barnard ...  \n",
              "3  i went to see this film with a great deal of e...  \n",
              "4  yes i agree with everyone on this site this mo...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "CEWVMOiItP2L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If we look at the data now, we'll not notice any punctuations in the **clean_review** column."
      ]
    },
    {
      "metadata": {
        "id": "PcKWqrLo2ZRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Word2Vec with Gensim(The Word2Vec toolkit)\n",
        "\n",
        "Gensim is an open source Python library for natural language processing, with a focus on topic modeling.Gensim was developed and is maintained by the Czech natural language processing researcher **Radim Řehůřek** and his company RaRe Technologies.\n",
        "\n",
        "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. Most notably for this tutorial, it supports an implementation of the** Word2Vec word embedding** for learning new word vectors from text.\n",
        "\n",
        "It also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, we dig a little \"deeper\" into sentiment analysis. Google's Word2Vec is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning and **semantic relationships** among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis."
      ]
    },
    {
      "metadata": {
        "id": "e4OuxlUSuPy7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Please install & import the gensim everytime you work on Google colab **"
      ]
    },
    {
      "metadata": {
        "id": "IK0rq-GZ-e45",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim --quiet                                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16M51r6GOuFC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IgGRlg9MuehZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Since we are going to work with words, so we are required to split the each review so that we can have word tokens.**"
      ]
    },
    {
      "metadata": {
        "id": "AtVP0tOb-fJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Document=[]\n",
        "for doc in df['clean_review']:\n",
        "  Document.append(doc.split(' '))                             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tta5zrdnrlft",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a10f7ff1-121c-4c8d-87f1-258ceeeb7ad5"
      },
      "cell_type": "code",
      "source": [
        "len(Document)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "Bfp2mtdQu8oU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let us explore split reviews**"
      ]
    },
    {
      "metadata": {
        "id": "SV4hRqzwVt4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f52824d-2cb5-4880-f16c-9e0efe05d82e"
      },
      "cell_type": "code",
      "source": [
        "Document[10][6:13]                                                                # This what is there in 10th Document starting from 6 till 12"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie', 'i', 'am', 'not', 'sure', 'whether', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "aQWDFXrYVt7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5d684567-36a0-467a-b6bf-b91bebbcdf81"
      },
      "cell_type": "code",
      "source": [
        "print(len(Document[10]))                                                          # Lenth of the 10th document ,  It has 524 words in it\n",
        "print(Document[10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "524\n",
            "['after', 'reading', 'the', 'comments', 'for', 'this', 'movie', 'i', 'am', 'not', 'sure', 'whether', 'i', 'should', 'be', 'angry', 'sad', 'or', 'sickened', 'seeing', 'comments', 'typical', 'of', 'people', 'who', 'a', 'know', 'absolutely', 'nothing', 'about', 'the', 'military', 'or', 'b', 'who', 'base', 'everything', 'they', 'think', 'they', 'know', 'on', 'movies', 'like', 'this', 'or', 'on', 'cnn', 'reports', 'about', 'abu', 'gharib', 'makes', 'me', 'wonder', 'about', 'the', 'state', 'of', 'intellectual', 'stimulation', 'in', 'the', 'world', 'br', 'br', 'at', 'the', 'time', 'i', 'type', 'this', 'the', 'number', 'of', 'people', 'in', 'the', 'us', 'military', 'million', 'on', 'active', 'duty', 'with', 'another', 'almost', 'in', 'the', 'guard', 'and', 'reserves', 'for', 'a', 'total', 'of', 'roughly', 'million', 'br', 'br', 'the', 'number', 'of', 'people', 'indicted', 'for', 'abuses', 'at', 'at', 'abu', 'gharib', 'currently', 'less', 'than', 'br', 'br', 'that', 'makes', 'the', 'total', 'of', 'people', 'indicted', 'of', 'the', 'total', 'military', 'even', 'if', 'you', 'indict', 'every', 'single', 'military', 'member', 'that', 'ever', 'stepped', 'in', 'to', 'abu', 'gharib', 'you', 'would', 'not', 'come', 'close', 'to', 'making', 'that', 'a', 'whole', 'number', 'br', 'br', 'the', 'flaws', 'in', 'this', 'movie', 'would', 'take', 'years', 'to', 'cover', 'i', 'understand', 'that', 'it', 's', 'supposed', 'to', 'be', 'sarcastic', 'but', 'in', 'reality', 'the', 'writer', 'and', 'director', 'are', 'trying', 'to', 'make', 'commentary', 'about', 'the', 'state', 'of', 'the', 'military', 'without', 'an', 'enemy', 'to', 'fight', 'in', 'reality', 'the', 'us', 'military', 'has', 'been', 'at', 'its', 'busiest', 'when', 'there', 'are', 'not', 'conflicts', 'going', 'on', 'the', 'military', 'is', 'the', 'first', 'called', 'for', 'disaster', 'relief', 'and', 'humanitarian', 'aid', 'missions', 'when', 'the', 'tsunami', 'hit', 'indonesia', 'devestating', 'the', 'region', 'the', 'us', 'military', 'was', 'the', 'first', 'on', 'the', 'scene', 'when', 'the', 'chaos', 'of', 'the', 'situation', 'overwhelmed', 'the', 'local', 'governments', 'it', 'was', 'military', 'leadership', 'who', 'looked', 'at', 'their', 'people', 'the', 'same', 'people', 'this', 'movie', 'mocks', 'and', 'said', 'make', 'it', 'happen', 'within', 'hours', 'food', 'aid', 'was', 'reaching', 'isolated', 'villages', 'within', 'days', 'airfields', 'were', 'built', 'cargo', 'aircraft', 'started', 'landing', 'and', 'a', 'food', 'distribution', 'system', 'was', 'up', 'and', 'running', 'hours', 'and', 'days', 'not', 'weeks', 'and', 'months', 'yes', 'there', 'are', 'unscrupulous', 'people', 'in', 'the', 'us', 'military', 'but', 'then', 'there', 'are', 'in', 'every', 'walk', 'of', 'life', 'every', 'occupation', 'but', 'to', 'see', 'people', 'on', 'this', 'website', 'decide', 'that', 'million', 'men', 'and', 'women', 'are', 'all', 'criminal', 'with', 'nothing', 'on', 'their', 'minds', 'but', 'thoughts', 'of', 'destruction', 'or', 'mayhem', 'is', 'an', 'absolute', 'disservice', 'to', 'the', 'things', 'that', 'they', 'do', 'every', 'day', 'one', 'person', 'on', 'this', 'website', 'even', 'went', 'so', 'far', 'as', 'to', 'say', 'that', 'military', 'members', 'are', 'in', 'it', 'for', 'personal', 'gain', 'wow', 'entry', 'level', 'personnel', 'make', 'just', 'under', 'an', 'hour', 'assuming', 'a', 'hour', 'work', 'week', 'of', 'course', 'many', 'work', 'much', 'more', 'than', 'hours', 'a', 'week', 'and', 'those', 'in', 'harm', 's', 'way', 'typically', 'put', 'in', 'hour', 'days', 'for', 'months', 'on', 'end', 'that', 'makes', 'the', 'pay', 'well', 'under', 'minimum', 'wage', 'so', 'much', 'for', 'personal', 'gain', 'i', 'beg', 'you', 'please', 'make', 'yourself', 'familiar', 'with', 'the', 'world', 'around', 'you', 'go', 'to', 'a', 'nearby', 'base', 'get', 'a', 'visitor', 'pass', 'and', 'meet', 'some', 'of', 'the', 'men', 'and', 'women', 'you', 'are', 'so', 'quick', 'to', 'disparage', 'you', 'would', 'be', 'surprised', 'the', 'military', 'no', 'longer', 'accepts', 'people', 'in', 'lieu', 'of', 'prison', 'time', 'they', 'require', 'a', 'minimum', 'of', 'a', 'ged', 'and', 'prefer', 'a', 'high', 'school', 'diploma', 'the', 'middle', 'ranks', 'are', 'expected', 'to', 'get', 'a', 'minimum', 'of', 'undergraduate', 'degrees', 'and', 'the', 'upper', 'ranks', 'are', 'encouraged', 'to', 'get', 'advanced', 'degrees']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jamR9vRCPJM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import logging                                                                    # Please import logging to keep & check information regarding word2vec transformation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0fdKWAs2VuAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2193
        },
        "outputId": "3f754a76-2f5a-447e-a926-26964f894a21"
      },
      "cell_type": "code",
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "model=gensim.models.Word2Vec(Document,                                           # List of reviews\n",
        "                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n",
        "                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n",
        "                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n",
        "                          window=5)                                              # 5 neighbors on the either side of a word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 09:33:02,225 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2018-08-07 09:33:02,232 : INFO : collecting all words and their counts\n",
            "2018-08-07 09:33:02,233 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-08-07 09:33:02,855 : INFO : PROGRESS: at sentence #10000, processed 2399440 words, keeping 51654 word types\n",
            "2018-08-07 09:33:03,530 : INFO : PROGRESS: at sentence #20000, processed 4835846 words, keeping 69077 word types\n",
            "2018-08-07 09:33:04,212 : INFO : PROGRESS: at sentence #30000, processed 7267977 words, keeping 81515 word types\n",
            "2018-08-07 09:33:04,908 : INFO : PROGRESS: at sentence #40000, processed 9669772 words, keeping 91685 word types\n",
            "2018-08-07 09:33:05,608 : INFO : collected 100479 word types from a corpus of 12084660 raw words and 50000 sentences\n",
            "2018-08-07 09:33:05,609 : INFO : Loading a fresh vocabulary\n",
            "2018-08-07 09:33:05,719 : INFO : effective_min_count=10 retains 28322 unique words (28% of original 100479, drops 72157)\n",
            "2018-08-07 09:33:05,720 : INFO : effective_min_count=10 leaves 11910457 word corpus (98% of original 12084660, drops 174203)\n",
            "2018-08-07 09:33:05,826 : INFO : deleting the raw counts dictionary of 100479 items\n",
            "2018-08-07 09:33:05,831 : INFO : sample=0.001 downsamples 49 most-common words\n",
            "2018-08-07 09:33:05,833 : INFO : downsampling leaves estimated 8817283 word corpus (74.0% of prior 11910457)\n",
            "2018-08-07 09:33:05,982 : INFO : estimated required memory for 28322 words and 50 dimensions: 25489800 bytes\n",
            "2018-08-07 09:33:05,983 : INFO : resetting layer weights\n",
            "2018-08-07 09:33:06,289 : INFO : training model with 4 workers on 28322 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-08-07 09:33:07,308 : INFO : EPOCH 1 - PROGRESS: at 5.60% examples, 488555 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:08,355 : INFO : EPOCH 1 - PROGRESS: at 11.32% examples, 485284 words/s, in_qsize 6, out_qsize 3\n",
            "2018-08-07 09:33:09,380 : INFO : EPOCH 1 - PROGRESS: at 17.26% examples, 488996 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:10,395 : INFO : EPOCH 1 - PROGRESS: at 23.14% examples, 493237 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:11,396 : INFO : EPOCH 1 - PROGRESS: at 28.59% examples, 491968 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:12,405 : INFO : EPOCH 1 - PROGRESS: at 34.12% examples, 490458 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:13,411 : INFO : EPOCH 1 - PROGRESS: at 39.67% examples, 491491 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:14,426 : INFO : EPOCH 1 - PROGRESS: at 45.14% examples, 490023 words/s, in_qsize 7, out_qsize 2\n",
            "2018-08-07 09:33:15,463 : INFO : EPOCH 1 - PROGRESS: at 50.92% examples, 490157 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:16,468 : INFO : EPOCH 1 - PROGRESS: at 56.58% examples, 491130 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:17,477 : INFO : EPOCH 1 - PROGRESS: at 62.05% examples, 490564 words/s, in_qsize 6, out_qsize 0\n",
            "2018-08-07 09:33:18,488 : INFO : EPOCH 1 - PROGRESS: at 67.75% examples, 490957 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:19,488 : INFO : EPOCH 1 - PROGRESS: at 73.47% examples, 491784 words/s, in_qsize 8, out_qsize 0\n",
            "2018-08-07 09:33:20,502 : INFO : EPOCH 1 - PROGRESS: at 79.23% examples, 491952 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:21,515 : INFO : EPOCH 1 - PROGRESS: at 84.80% examples, 491708 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:22,528 : INFO : EPOCH 1 - PROGRESS: at 90.67% examples, 492403 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:23,541 : INFO : EPOCH 1 - PROGRESS: at 96.19% examples, 491983 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:24,148 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-08-07 09:33:24,164 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-08-07 09:33:24,174 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-08-07 09:33:24,181 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-08-07 09:33:24,183 : INFO : EPOCH - 1 : training on 12084660 raw words (8816219 effective words) took 17.9s, 492921 effective words/s\n",
            "2018-08-07 09:33:25,212 : INFO : EPOCH 2 - PROGRESS: at 5.59% examples, 483101 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:26,247 : INFO : EPOCH 2 - PROGRESS: at 11.48% examples, 488437 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:27,255 : INFO : EPOCH 2 - PROGRESS: at 17.17% examples, 489443 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:28,257 : INFO : EPOCH 2 - PROGRESS: at 22.82% examples, 489880 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:29,283 : INFO : EPOCH 2 - PROGRESS: at 28.51% examples, 491079 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:30,292 : INFO : EPOCH 2 - PROGRESS: at 34.13% examples, 490832 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:31,292 : INFO : EPOCH 2 - PROGRESS: at 39.75% examples, 493243 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:32,298 : INFO : EPOCH 2 - PROGRESS: at 45.29% examples, 492994 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:33,307 : INFO : EPOCH 2 - PROGRESS: at 50.99% examples, 493584 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:34,324 : INFO : EPOCH 2 - PROGRESS: at 56.65% examples, 493610 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:35,347 : INFO : EPOCH 2 - PROGRESS: at 62.36% examples, 494088 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:36,365 : INFO : EPOCH 2 - PROGRESS: at 68.23% examples, 495129 words/s, in_qsize 7, out_qsize 1\n",
            "2018-08-07 09:33:37,378 : INFO : EPOCH 2 - PROGRESS: at 74.04% examples, 495698 words/s, in_qsize 5, out_qsize 2\n",
            "2018-08-07 09:33:38,385 : INFO : EPOCH 2 - PROGRESS: at 79.97% examples, 496821 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:39,409 : INFO : EPOCH 2 - PROGRESS: at 85.69% examples, 496389 words/s, in_qsize 5, out_qsize 2\n",
            "2018-08-07 09:33:40,425 : INFO : EPOCH 2 - PROGRESS: at 91.63% examples, 497537 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:41,434 : INFO : EPOCH 2 - PROGRESS: at 97.24% examples, 497405 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:41,868 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-08-07 09:33:41,878 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-08-07 09:33:41,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-08-07 09:33:41,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-08-07 09:33:41,896 : INFO : EPOCH - 2 : training on 12084660 raw words (8817022 effective words) took 17.7s, 497911 effective words/s\n",
            "2018-08-07 09:33:42,913 : INFO : EPOCH 3 - PROGRESS: at 5.59% examples, 494195 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:43,938 : INFO : EPOCH 3 - PROGRESS: at 11.57% examples, 499956 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:44,957 : INFO : EPOCH 3 - PROGRESS: at 17.43% examples, 499872 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:33:45,980 : INFO : EPOCH 3 - PROGRESS: at 23.30% examples, 500724 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:46,988 : INFO : EPOCH 3 - PROGRESS: at 28.98% examples, 501482 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:48,014 : INFO : EPOCH 3 - PROGRESS: at 34.75% examples, 500540 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:49,016 : INFO : EPOCH 3 - PROGRESS: at 40.20% examples, 499383 words/s, in_qsize 8, out_qsize 3\n",
            "2018-08-07 09:33:50,018 : INFO : EPOCH 3 - PROGRESS: at 45.93% examples, 500347 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:51,029 : INFO : EPOCH 3 - PROGRESS: at 51.81% examples, 501548 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:52,063 : INFO : EPOCH 3 - PROGRESS: at 57.48% examples, 500150 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:53,082 : INFO : EPOCH 3 - PROGRESS: at 63.22% examples, 500745 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:54,107 : INFO : EPOCH 3 - PROGRESS: at 69.03% examples, 500333 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:55,118 : INFO : EPOCH 3 - PROGRESS: at 74.82% examples, 500534 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:56,134 : INFO : EPOCH 3 - PROGRESS: at 80.71% examples, 500517 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:57,135 : INFO : EPOCH 3 - PROGRESS: at 86.53% examples, 501061 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:58,162 : INFO : EPOCH 3 - PROGRESS: at 92.27% examples, 500724 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:59,184 : INFO : EPOCH 3 - PROGRESS: at 98.08% examples, 500844 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:33:59,463 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-08-07 09:33:59,473 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-08-07 09:33:59,481 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-08-07 09:33:59,497 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-08-07 09:33:59,499 : INFO : EPOCH - 3 : training on 12084660 raw words (8817308 effective words) took 17.6s, 501404 effective words/s\n",
            "2018-08-07 09:34:00,520 : INFO : EPOCH 4 - PROGRESS: at 5.60% examples, 485680 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:01,523 : INFO : EPOCH 4 - PROGRESS: at 11.50% examples, 497608 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:02,524 : INFO : EPOCH 4 - PROGRESS: at 17.26% examples, 499124 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:03,529 : INFO : EPOCH 4 - PROGRESS: at 22.90% examples, 496708 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:04,546 : INFO : EPOCH 4 - PROGRESS: at 28.58% examples, 497532 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:05,568 : INFO : EPOCH 4 - PROGRESS: at 34.45% examples, 498775 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:06,570 : INFO : EPOCH 4 - PROGRESS: at 40.13% examples, 500781 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:07,614 : INFO : EPOCH 4 - PROGRESS: at 45.85% examples, 499054 words/s, in_qsize 8, out_qsize 2\n",
            "2018-08-07 09:34:08,655 : INFO : EPOCH 4 - PROGRESS: at 51.81% examples, 499520 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:09,667 : INFO : EPOCH 4 - PROGRESS: at 57.48% examples, 499333 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:10,676 : INFO : EPOCH 4 - PROGRESS: at 63.13% examples, 499835 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:11,680 : INFO : EPOCH 4 - PROGRESS: at 68.95% examples, 500376 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:12,685 : INFO : EPOCH 4 - PROGRESS: at 74.66% examples, 500285 words/s, in_qsize 7, out_qsize 1\n",
            "2018-08-07 09:34:13,710 : INFO : EPOCH 4 - PROGRESS: at 80.46% examples, 499460 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:14,713 : INFO : EPOCH 4 - PROGRESS: at 86.20% examples, 499543 words/s, in_qsize 8, out_qsize 0\n",
            "2018-08-07 09:34:15,716 : INFO : EPOCH 4 - PROGRESS: at 91.93% examples, 500036 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:16,726 : INFO : EPOCH 4 - PROGRESS: at 97.47% examples, 499296 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:34:17,115 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-08-07 09:34:17,116 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-08-07 09:34:17,126 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-08-07 09:34:17,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-08-07 09:34:17,132 : INFO : EPOCH - 4 : training on 12084660 raw words (8817015 effective words) took 17.6s, 500142 effective words/s\n",
            "2018-08-07 09:34:18,144 : INFO : EPOCH 5 - PROGRESS: at 5.52% examples, 483181 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:34:19,177 : INFO : EPOCH 5 - PROGRESS: at 11.48% examples, 492966 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:20,199 : INFO : EPOCH 5 - PROGRESS: at 17.40% examples, 497248 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:21,204 : INFO : EPOCH 5 - PROGRESS: at 23.22% examples, 499011 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:22,204 : INFO : EPOCH 5 - PROGRESS: at 28.74% examples, 498120 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:23,222 : INFO : EPOCH 5 - PROGRESS: at 34.45% examples, 497175 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:24,223 : INFO : EPOCH 5 - PROGRESS: at 39.96% examples, 497489 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:25,228 : INFO : EPOCH 5 - PROGRESS: at 45.68% examples, 498583 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:26,229 : INFO : EPOCH 5 - PROGRESS: at 51.39% examples, 498945 words/s, in_qsize 8, out_qsize 0\n",
            "2018-08-07 09:34:27,250 : INFO : EPOCH 5 - PROGRESS: at 57.06% examples, 498353 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:28,255 : INFO : EPOCH 5 - PROGRESS: at 62.59% examples, 497801 words/s, in_qsize 6, out_qsize 1\n",
            "2018-08-07 09:34:29,257 : INFO : EPOCH 5 - PROGRESS: at 68.31% examples, 498004 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:30,267 : INFO : EPOCH 5 - PROGRESS: at 74.12% examples, 498480 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:31,283 : INFO : EPOCH 5 - PROGRESS: at 79.90% examples, 498111 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:32,295 : INFO : EPOCH 5 - PROGRESS: at 85.69% examples, 498447 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:33,329 : INFO : EPOCH 5 - PROGRESS: at 91.56% examples, 498458 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:34,339 : INFO : EPOCH 5 - PROGRESS: at 97.24% examples, 498656 words/s, in_qsize 7, out_qsize 0\n",
            "2018-08-07 09:34:34,763 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2018-08-07 09:34:34,777 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-08-07 09:34:34,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-08-07 09:34:34,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-08-07 09:34:34,799 : INFO : EPOCH - 5 : training on 12084660 raw words (8817341 effective words) took 17.7s, 499216 effective words/s\n",
            "2018-08-07 09:34:34,800 : INFO : training on a 60423300 raw words (44084905 effective words) took 88.5s, 498073 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dHlVJEoXC5PD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Please note that after applying Word2Vec function on the clean_review giving all the arguments corretly we have got 28322 words**"
      ]
    },
    {
      "metadata": {
        "id": "9RYnV85LCq3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "894d2ede-a7a2-4ca5-eab1-c7fec4e695d5"
      },
      "cell_type": "code",
      "source": [
        "print(len(model.wv.vocab))                                                        # Now the vocab contains 28322 uinque words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mdk_HDQWD0ct",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's check the dimension of a vector i.e. the number of words that represent a word**"
      ]
    },
    {
      "metadata": {
        "id": "8DGahs80Dv6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29bf76f4-2af1-452b-e897-d58738ab43b7"
      },
      "cell_type": "code",
      "source": [
        "print(model.wv.vector_size)                                                       # It means each vector has 50 numbers in it or in other words each word is vector of 5o numbers that we predefined"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BqmrT73MQsgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3876a7c-82e1-4865-aa9e-0c47a9b66f18"
      },
      "cell_type": "code",
      "source": [
        "model.wv.vectors.shape                                                            # Dimension of the the entire corpus        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28322, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "yhGHd2OREPSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's explore some interesting results of word2vec experiment\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Db44U_SoVuC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "f93abe9d-6280-436a-c399-e8c7fb981a36"
      },
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"beautiful\")                                                # 10 similar words beautiful,the maximum similarity is 1,minimum is 0.When they are completely similar the \n",
        "                                                                                  # Value will be 1 , when completely dissimilar,the value will be 0."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 09:35:08,657 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8471376299858093),\n",
              " ('lovely', 0.8315596580505371),\n",
              " ('stunning', 0.8191053867340088),\n",
              " ('wonderful', 0.765620231628418),\n",
              " ('haunting', 0.7359098196029663),\n",
              " ('delightful', 0.6994979381561279),\n",
              " ('exquisite', 0.698267936706543),\n",
              " ('fabulous', 0.6927884817123413),\n",
              " ('magnificent', 0.6914386749267578),\n",
              " ('breathtaking', 0.6781392693519592)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "4NbHKeQg6kP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2f83f13a-03f5-432f-9c04-4369aca5a43c"
      },
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"princess\")                                                  # 10 similar words returned with numbers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('maid', 0.8509283661842346),\n",
              " ('widow', 0.8461511731147766),\n",
              " ('nurse', 0.8181332945823669),\n",
              " ('nina', 0.8052970170974731),\n",
              " ('prince', 0.8045807480812073),\n",
              " ('marie', 0.8042115569114685),\n",
              " ('queen', 0.7979417443275452),\n",
              " ('belle', 0.796779990196228),\n",
              " ('rose', 0.793120265007019),\n",
              " ('alice', 0.7904024720191956)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "R-tDNwJD-fQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "db598520-06c7-4b2b-b088-f6a3d56102dc"
      },
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match(\"she talked to me in the evening publicly\".split())         # publicly does not match in the sentence given"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'publicly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "I3lClNUZFpQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below the word **right** is represented by a dense 50 dimensional vector"
      ]
    },
    {
      "metadata": {
        "id": "-sj-zNbJ6kKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0cd34458-a313-4976-f1f5-ac4a9f81efa5"
      },
      "cell_type": "code",
      "source": [
        "model.wv[\"right\"]                                                                  # right word is represented by 50 numbers in other words the word \"right\" is vector of 50 numbers\n",
        "                                                                                   # 50 numbers are summarized weights because these numbers are obtained in the hidden layer of predefined 50 neurons"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.45915538,  0.06086664,  0.01259037, -2.1245008 , -0.72445613,\n",
              "       -1.5176048 ,  0.23959297, -0.01427053,  3.7613926 , -0.6453895 ,\n",
              "        1.638466  , -1.3965507 , -0.23434123, -0.14534447,  0.45508638,\n",
              "       -0.2178561 , -0.08167738,  2.1209497 ,  1.4102764 , -0.31947896,\n",
              "       -1.6591879 ,  1.4027224 ,  2.2697747 , -2.4618444 ,  0.12646163,\n",
              "       -1.4955904 ,  0.22472405, -0.4817074 , -1.570508  ,  1.6831069 ,\n",
              "       -2.9324646 ,  0.2946715 ,  0.99710435, -0.94695747,  0.30391267,\n",
              "        1.2408613 ,  1.795748  ,  2.1296551 , -0.22710651, -1.7150404 ,\n",
              "        0.7432551 ,  1.7634066 ,  1.2548078 , -0.12498467, -1.286492  ,\n",
              "        1.2944527 , -0.35894206,  0.8585205 ,  0.67597824,  0.33245698],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "ZnENAcilu0pP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "03800729-9362-4a61-9bc2-f2cd25ecbabb"
      },
      "cell_type": "code",
      "source": [
        "model.wv['great']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.6015653 ,  0.61710984,  3.2100782 , -1.382224  ,  3.8332994 ,\n",
              "       -1.5283953 , -1.757213  , -0.9150323 ,  0.71562743, -1.490887  ,\n",
              "       -1.079873  , -3.9077005 ,  0.14639786, -1.609733  ,  0.2366714 ,\n",
              "       -2.5148401 ,  1.794771  ,  0.8459636 , -3.4906342 , -0.8838494 ,\n",
              "       -1.83148   ,  0.64605296,  0.3943065 ,  0.08203562, -0.87866503,\n",
              "       -1.4840964 ,  0.13530625,  0.8985208 , -2.1363556 ,  2.210215  ,\n",
              "       -1.5091558 , -0.82171273, -0.08659384, -1.3204099 , -0.30402672,\n",
              "        1.1808782 ,  5.113552  ,  1.3619634 ,  1.2964532 , -2.978569  ,\n",
              "       -1.8495582 ,  0.4808531 ,  0.11318186,  0.09366827, -3.990861  ,\n",
              "        0.23104067, -0.02458301,  1.8092113 , -1.8071944 ,  0.2836727 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "CItdPnnHGk66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving the model"
      ]
    },
    {
      "metadata": {
        "id": "_MMsUOIp-fNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c044b18f-5de9-42cd-b27d-26053a3d09fb"
      },
      "cell_type": "code",
      "source": [
        "model.save(\"word2vec movie-50\")                                                    # We save this model for further use.\n",
        "                                                                                   # Google has such many pre-trained models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 08:46:57,134 : INFO : saving Word2Vec object under word2vec movie-50, separately None\n",
            "2018-08-07 08:46:57,136 : INFO : not storing attribute vectors_norm\n",
            "2018-08-07 08:46:57,138 : INFO : not storing attribute cum_table\n",
            "2018-08-07 08:46:57,356 : INFO : saved word2vec movie-50\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "5a1G2kw_6kf2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GUgohwEuWlY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis with pre-trained Word2Vec model "
      ]
    },
    {
      "metadata": {
        "id": "TAQXgw03nEXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "In this tutorial we'll do Sentiment analysis based on the concept of Word2Vec using our **pre-trained model** with unlabelled data where we've applied **Word2Vec** technique i.e representing a word with a dense vector of **50 numbers**. The unlabelled data has **50000 IMDB movie reviews** & we extracted  some **28000+** unique words after doing some data preprocessing & applying Word2Vec technique with length of 50 numbers."
      ]
    },
    {
      "metadata": {
        "id": "-9hFkqqmnKqC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Set the seed"
      ]
    },
    {
      "metadata": {
        "id": "BXb44GXhnSkt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91e2PZR_nX-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Load data\n",
        "Data can be downloaded from Kaggle -> https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "metadata": {
        "id": "Ov9QKZFTnTUu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9980ca75-c3b3-4a4f-cb76-35226b0c155f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c64d72a-275d-42a4-b5f7-7181ada93ace\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8c64d72a-275d-42a4-b5f7-7181ada93ace\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving labeledTrainData.tsv to labeledTrainData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T21NoUqcnald",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "551e7ec5-77f2-4970-a46c-5923081c4475"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('labeledTrainData.tsv',  #filepath\n",
        "                 header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "print(df1.shape)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zP7Bh8CXnq8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## About the data\n",
        "\n",
        "The labelled data set contains 25000 reviews with label(**Sentiment**). The output column  Sentiment consists of 2 categories[0 & 1]. \n",
        "\n",
        "**0 -- Indicates negative sentiment **               ,  if the rating < 5\n",
        "\n",
        "**1-- Indicates positive sentiment **                  , if the rating >= 7"
      ]
    },
    {
      "metadata": {
        "id": "537_Pz8Rnaoy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "78fcf3e1-ba6d-4d13-9199-3cb4d6504c5f"
      },
      "cell_type": "code",
      "source": [
        "df1.iloc[10:15,:]                                                                  # Have 10th & 11th review of the dataset alongwith review id, sentiment."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"11744_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\"7369_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I had a feeling that after \\\"Submerged\\\", thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\"12081_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"note to George Litman, and others: the Myster...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli...\n",
              "12  \"11744_9\"          1  \"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...\n",
              "13   \"7369_1\"          0  \"I had a feeling that after \\\"Submerged\\\", thi...\n",
              "14  \"12081_1\"          0  \"note to George Litman, and others: the Myster..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "id": "DA0WOP_Mn0s0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "uyBpzQpIn6i9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1.Split Data into Training and Test Data**"
      ]
    },
    {
      "metadata": {
        "id": "UipXytQsnary",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df1['review'],\n",
        "    df1['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GaoXClWoCYz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2.Build Tokenizer to get Number sequences for Each review**"
      ]
    },
    {
      "metadata": {
        "id": "B5cQEWFenaut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vocab size\n",
        "top_words = 10000\n",
        "\n",
        "t = Tokenizer(num_words=top_words)\n",
        "t.fit_on_texts(X_train.tolist())\n",
        "\n",
        "#Get the word index for each of the word in the review\n",
        "X_train = t.texts_to_sequences(X_train.tolist())\n",
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOEpL98doNTN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3.Pad sequences to make each review size equal Get the word index for each of the word in the review**\n",
        "\n",
        "We  want to bring all the reviewa into same length because we want to build matrix with this dimension"
      ]
    },
    {
      "metadata": {
        "id": "NqXkimj3oXTT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "\n",
        "#Each review size\n",
        "max_review_length = 300\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uoZCpIZeoc34",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build Embedding Matrix from Pre-Trained Word2Vec model"
      ]
    },
    {
      "metadata": {
        "id": "G5xftICooe2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5b53fdc7-97f5-44d5-8e12-56ee4ba638d9"
      },
      "cell_type": "code",
      "source": [
        "#Install gensim\n",
        "!pip install gensim --quiet\n",
        "\n",
        "#Load pre-trained model\n",
        "import gensim\n",
        "word2vec = gensim.models.Word2Vec.load('word2vec movie-50')\n",
        "\n",
        "#Embedding Length\n",
        "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
        "\n",
        "print('Loaded word2vec model..')\n",
        "print('Model shape: ', word2vec.wv.vectors.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 10:03:28,370 : INFO : loading Word2Vec object from word2vec movie-50\n",
            "2018-08-07 10:03:28,543 : INFO : loading wv recursively from word2vec movie-50.wv.* with mmap=None\n",
            "2018-08-07 10:03:28,544 : INFO : setting ignored attribute vectors_norm to None\n",
            "2018-08-07 10:03:28,545 : INFO : loading vocabulary recursively from word2vec movie-50.vocabulary.* with mmap=None\n",
            "2018-08-07 10:03:28,552 : INFO : loading trainables recursively from word2vec movie-50.trainables.* with mmap=None\n",
            "2018-08-07 10:03:28,554 : INFO : setting ignored attribute cum_table to None\n",
            "2018-08-07 10:03:28,557 : INFO : loaded word2vec movie-50\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded word2vec model..\n",
            "Model shape:  (28322, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OvXA1a5Zop5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e1d9e6d-bf47-4444-ff7e-b325fc2d41e8"
      },
      "cell_type": "code",
      "source": [
        "word2vec.wv.vector_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "xxuznkdnowdn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Build matrix for current data**"
      ]
    },
    {
      "metadata": {
        "id": "Q5zL8xsAop-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize embedding matrix to all zeros\n",
        "embedding_matrix = np.zeros((top_words + 1, # Vocablury size + 1,, we add 1 to vocab size for padding\n",
        "                             embedding_vector_length))\n",
        "\n",
        "#Steps for populating embedding matrix\n",
        "\n",
        "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
        "# word2vec model.\n",
        "#2. If found, update embedding matrix with embeddings for the word \n",
        "# from word2vec model\n",
        "\n",
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > top_words:\n",
        "        break\n",
        "    if word in word2vec.wv.vocab:\n",
        "        embedding_vector = word2vec.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZzFuBkzoqBA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6dbc86c5-bbc8-4e75-9aaa-fc89995385ee"
      },
      "cell_type": "code",
      "source": [
        "#Check embeddings for word 'great'\n",
        "embedding_matrix[t.word_index['great']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.59144205,  0.94809264,  2.92205071, -2.57998848,  2.06668258,\n",
              "        0.03379907, -2.07701755, -1.28192663,  2.37326407, -1.6968323 ,\n",
              "       -1.46692789, -2.43406081, -0.99238962, -2.35702658,  0.37269598,\n",
              "       -1.23948109,  1.67976511,  1.22183132, -2.27092576, -0.52730691,\n",
              "        2.21310592,  3.8952992 , -1.38157284, -0.99453694, -0.90861291,\n",
              "       -1.57382619, -0.62930226,  1.70807695, -1.20810831,  2.12286615,\n",
              "       -0.50363177, -0.57258892, -0.01908715, -2.85462713,  0.36451188,\n",
              "        0.2708773 ,  3.52137017,  2.90140653,  2.48585653, -2.98677659,\n",
              "       -1.01710439,  1.52898908, -0.93782079,  0.80436903, -3.12551713,\n",
              "        1.43007016,  2.68136525,  1.97543514,  0.14813299,  2.30020237])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "metadata": {
        "id": "JjgKk9JprPvc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "metadata": {
        "id": "Z6oNRfbcoqDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten\n",
        "\n",
        "#Build a sequential model\n",
        "model1 = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NpXa42e0rYoc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Add Embedding layer**"
      ]
    },
    {
      "metadata": {
        "id": "I9FUNpgeoqGe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1.add(Embedding(top_words + 1,\n",
        "                    embedding_vector_length,\n",
        "                    input_length=max_review_length,\n",
        "                    weights=[embedding_matrix],                                    # Pre-trained embedding\n",
        "                    trainable=False)                                               # We do not want to change embedding\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFsjGhSXrw7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Output from Embedding is 3 dimension \n",
        "- batch_size x max_review_length x embedding_vector_length. \n",
        "\n",
        "We need to flatten the output for Dense layer"
      ]
    },
    {
      "metadata": {
        "id": "esaAPDRioqLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Flatten embedding layer output and flatten layers\n",
        "model1.add(Flatten())                                                             # Flatten enables us to bring down the dimension of the prepared data\n",
        "model1.add(Dense(200,activation='relu'))                                          # Dense layer is for fully connected layer\n",
        "model1.add(Dense(100,activation='relu'))\n",
        "model1.add(Dropout(0.5))                                                          # Dropout is required to avoid overfiting & make the model generalize\n",
        "model1.add(Dense(60,activation='relu'))\n",
        "model1.add(Dropout(0.4))\n",
        "model1.add(Dense(30,activation='relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(1,activation='sigmoid'))                                         # We've used sigmoid because output variable is binary\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q3KyXjkXxdxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from keras.utils import to_categorical\n",
        "#Y_train=to_categorical(y_train,2)\n",
        "#Y_test=to_categorical(y_test,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xH1o_Swr98W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Execute the graph\n",
        "\n",
        "Here we'll  use split data to find train & validation accuracy with 10 iterations on 20000 train data & 5000 validation data with batch size of 200."
      ]
    },
    {
      "metadata": {
        "id": "n56qw2p1oqJo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "653956e2-bac7-4edb-fc02-3b186c31af54"
      },
      "cell_type": "code",
      "source": [
        "model1.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=200,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 11s 568us/step - loss: 0.7227 - acc: 0.5473 - val_loss: 0.6284 - val_acc: 0.6926\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 10s 488us/step - loss: 0.5602 - acc: 0.7196 - val_loss: 0.5279 - val_acc: 0.7364\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 10s 491us/step - loss: 0.4260 - acc: 0.8138 - val_loss: 0.5049 - val_acc: 0.7600\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 10s 490us/step - loss: 0.3235 - acc: 0.8696 - val_loss: 0.5206 - val_acc: 0.7528\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 10s 490us/step - loss: 0.2279 - acc: 0.9125 - val_loss: 0.6552 - val_acc: 0.7508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0962e4ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "metadata": {
        "id": "pAVyObUcLqV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}