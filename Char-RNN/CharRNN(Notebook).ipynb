{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CharRNN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2OOa769l7vGn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Table of Contents\n",
        "**1. Character RNN**\n",
        "\n",
        "**2. The data**\n",
        "\n",
        "**3. Data Preprocessing**\n",
        "\n",
        "**4. Build the model**\n",
        "\n",
        "**5. Build the predict sequence**\n",
        "\n",
        "**6. Prediction**"
      ]
    },
    {
      "metadata": {
        "id": "GgOvxsEafRIy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Character RNN\n",
        "\n",
        "The term “char-rnn” is short for “character recurrent neural network”, and is effectively a recurrent neural network trained to predict the next character given a sequence of previous characters. In this way, we can think of a char-rnn as a classification model. For a char-rnn we wish to output a probability distribution over character classes, i.e., a vocabulary of characters. In this setting we are given the characters one at a time and only expected to predict an output after the last character.\n",
        "\n",
        "Below is an example of charRNN\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"250\" width=\"450\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=165c82544a6ca2b7&attid=0.1&disp=safe&realattid=f_jlxkex7n1&zw\"></img>\n",
        "\n",
        "\n",
        "In the example above we have 5 timesteps i.e. length of of the sequence is 5 and we'll get output after passing 5 characters. \n",
        "\n",
        "\n",
        "**Use of Char-RNN:**\n",
        "\n",
        "<p align=\"center\">\n",
        "<img height=\"250\" width=\"450\" src=\"https://mail.google.com/mail/u/0/?ui=2&ik=0aefe2754b&view=att&th=165c932922d81ce0&attid=0.1&disp=safe&realattid=f_jlxux5xs1&zw\"></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KUT-UwsBOadG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. The Data\n",
        "## Download the data & read in colab in the following format\n",
        "\n",
        "The book was collected from Gutenberg corpus available in the link below & opened in colab with the following command "
      ]
    },
    {
      "metadata": {
        "id": "sAk6RAc6R7fI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bff1a3dc-11e8-4e3e-fe8a-431e2baab281"
      },
      "cell_type": "code",
      "source": [
        "#Download book\n",
        "!wget -O Pride_and_Prejudice.txt http://www.gutenberg.org/files/1342/1342-0.txt --quiet\n",
        "text_book=open(\"Pride_and_Prejudice.txt\",encoding='utf8').read()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z3OURgI7OpT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's have a look at the first 23 characters of the book"
      ]
    },
    {
      "metadata": {
        "id": "tuBfksSGR94d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8d634d5-efe4-4fea-a7aa-d698d5d83c27"
      },
      "cell_type": "code",
      "source": [
        "text_book[:23]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffThe Project Gutenberg '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "O1z6KKGg-w4E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "HqrNOb2ER9-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer                                   # Tokenizer class of keras is imported to tokenize each character "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bGkixQaRR-DY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t=Tokenizer(char_level=True)                                                     # we want character level equal to True because it's all about characters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rmVzEAyYR-C0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "t.fit_on_texts(text_book)                                                        # We need to fit the entire book on text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHmTuI5hR99u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f5572ac-f136-4585-f215-179b6052fc1b"
      },
      "cell_type": "code",
      "source": [
        "vocab_size=len(t.word_index)\n",
        "vocab_size                                                                       # we want to find number of unique characters in the book"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "6vWVOLKGTfcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "book_num=t.texts_to_sequences(text_book)                                         # Characters are converted into numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnyryWE1Tffw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d580cf08-b451-4b6a-967f-7c9caf86278f"
      },
      "cell_type": "code",
      "source": [
        "book_length=len(book_num)\n",
        "book_length                                                                      # The book has 704190 characters in it"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "704190"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "ld2KMZ3-UslN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_length=100                                                              # After each 100 characters, we want a output(a character)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zCA-Nwn5TfiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1479
        },
        "outputId": "8653e151-5dc4-4e0b-c13b-19e3fb4d327f"
      },
      "cell_type": "code",
      "source": [
        "unique_chars=t.word_index                                                        # Find the index number of each of the 86 characters. Space ' ' is also considered\n",
        "unique_chars                                                                     # a character\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 14,\n",
              " ' ': 1,\n",
              " '!': 49,\n",
              " '#': 83,\n",
              " '$': 80,\n",
              " '%': 85,\n",
              " \"'\": 40,\n",
              " '(': 64,\n",
              " ')': 65,\n",
              " '*': 63,\n",
              " ',': 21,\n",
              " '-': 32,\n",
              " '.': 24,\n",
              " '/': 72,\n",
              " '0': 69,\n",
              " '1': 61,\n",
              " '2': 66,\n",
              " '3': 67,\n",
              " '4': 68,\n",
              " '5': 71,\n",
              " '6': 74,\n",
              " '7': 76,\n",
              " '8': 73,\n",
              " '9': 75,\n",
              " ':': 59,\n",
              " ';': 31,\n",
              " '?': 50,\n",
              " '@': 79,\n",
              " 'A': 48,\n",
              " 'B': 33,\n",
              " 'C': 42,\n",
              " 'D': 46,\n",
              " 'E': 37,\n",
              " 'F': 57,\n",
              " 'G': 55,\n",
              " 'H': 41,\n",
              " 'I': 27,\n",
              " 'J': 52,\n",
              " 'K': 60,\n",
              " 'L': 39,\n",
              " 'M': 30,\n",
              " 'N': 54,\n",
              " 'O': 56,\n",
              " 'P': 53,\n",
              " 'Q': 86,\n",
              " 'R': 58,\n",
              " 'S': 47,\n",
              " 'T': 35,\n",
              " 'U': 62,\n",
              " 'V': 70,\n",
              " 'W': 43,\n",
              " 'X': 78,\n",
              " 'Y': 51,\n",
              " 'Z': 77,\n",
              " '[': 82,\n",
              " ']': 84,\n",
              " '_': 38,\n",
              " 'a': 4,\n",
              " 'b': 23,\n",
              " 'c': 16,\n",
              " 'd': 11,\n",
              " 'e': 2,\n",
              " 'f': 18,\n",
              " 'g': 20,\n",
              " 'h': 8,\n",
              " 'i': 7,\n",
              " 'j': 44,\n",
              " 'k': 26,\n",
              " 'l': 12,\n",
              " 'm': 15,\n",
              " 'n': 6,\n",
              " 'o': 5,\n",
              " 'p': 22,\n",
              " 'q': 45,\n",
              " 'r': 9,\n",
              " 's': 10,\n",
              " 't': 3,\n",
              " 'u': 13,\n",
              " 'v': 25,\n",
              " 'w': 19,\n",
              " 'x': 36,\n",
              " 'y': 17,\n",
              " 'z': 34,\n",
              " '“': 28,\n",
              " '”': 29,\n",
              " '\\ufeff': 81}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "JGY7iQ_AAEqg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare input & output data"
      ]
    },
    {
      "metadata": {
        "id": "LYmqa27-Tfkz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data=[]                                                                     # Create empty list both for input & output data\n",
        "output_data=[]\n",
        "for i in range(0,book_length-sequence_length):\n",
        "  input_seq=book_num[i:i+sequence_length]\n",
        "  output_seq=book_num[i+sequence_length]\n",
        "  input_data.append(input_seq)\n",
        "  output_data.append(output_seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9hHkDi3LWLVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8285115e-2a36-4a7d-da18-289100f527c9"
      },
      "cell_type": "code",
      "source": [
        "print(len(input_data[0]))                                                        # As mentioned earlier input data has 100 characters\n",
        "print(len(output_data[3]))                                                       # Whereas output data has 1 character. After each input data(100 chars) we'll get 1 \n",
        "                                                                                 # character as output "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NDbIlnAMUNSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9dad8aa2-395d-4647-aa82-81a0219b2bfa"
      },
      "cell_type": "code",
      "source": [
        "print(len(input_data))\n",
        "print(len(output_data))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "704090\n",
            "704090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WhHjFOsvX731",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data=np.reshape(input_data,(len(input_data),len(input_data[2]),1))         # reshape the input data into 3 dimensions, each example contains a sequence of 100\n",
        "                                                                                 # characters & 1 denotes , each character is represented by 1 number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u-XCZeD6v-IF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_data=input_data/vocab_size                                                 # Normalize the input data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k6tK2so_s_kO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faa0cfe1-3d60-46df-f117-37a15dd96409"
      },
      "cell_type": "code",
      "source": [
        "input_data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(704090, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "klgFtMWcwu6u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical                                           # One-hot encoding is done for each character because \n",
        "output_data=to_categorical(output_data,num_classes=vocab_size+1)                 # We want one one character to be predicted out of 86 unique characters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GCZS1ESxRNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "260daee9-ad75-4427-b2c1-943b9ff71902"
      },
      "cell_type": "code",
      "source": [
        "output_data[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "L_YsZaJRDAhy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Build the model"
      ]
    },
    {
      "metadata": {
        "id": "Sf3fDM-oUNVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential                                              # Import the following to proceed further analysis\n",
        "from keras.layers import Dense,LSTM,Dropout                                                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OoJtCeEhUNYT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "POjJnlkuUNa_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(LSTM(256,input_shape=(input_data.shape[1],input_data.shape[2])))       # 256 is the memory size of LSTM layer.input_data.shape[1]=100 is the timesteps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9gI2tZ8UNde",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dropout(0.2))                                                          # Dropout is used to reduce overfiting.In Dropout we drop some neurones for the\n",
        "                                                                                 # next layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JZKq4Cr9xwyo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(vocab_size+1,activation=\"softmax\"))                              # since it's multiclass classification i.e each input has 1 output out of  86 chars,\n",
        "                                                                                 # so we'll use softmax classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AY79fWm5UNgM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\")                  # We are not concerned with accuracy. We check model performance based on the loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41IZmqv3UNi_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2c1407cb-0a0f-4d8f-a80f-aae0871f1ea9"
      },
      "cell_type": "code",
      "source": [
        "model.fit(input_data,output_data,epochs=3,batch_size=2048)                       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "704090/704090 [==============================] - 3186s 5ms/step - loss: 3.1277\n",
            "Epoch 2/3\n",
            "704090/704090 [==============================] - 3189s 5ms/step - loss: 3.0957\n",
            "Epoch 3/3\n",
            "704090/704090 [==============================] - 3163s 4ms/step - loss: 3.0224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3eb5dd828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "9UVu4155JW4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.  Build the predict sequence"
      ]
    },
    {
      "metadata": {
        "id": "Zxn7_kQ8Yc4m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_seq=input_data[np.random.randint(0,high=input_data.shape[0])]               # test_seq is a seq of 100 characters & each number is represented by 1 number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlGBbtPrKIP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d6261ae-5de7-4ad4-8f4c-4229cbfb8204"
      },
      "cell_type": "code",
      "source": [
        "test_seq.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "-UPOtmUjYc7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "int_to_char = dict((i,c) for c, i in t.word_index.items())                       #Build a dictionary which can convert numbers into chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJC1BPlVCbs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bbcfa30d-b55e-4890-bb41-e7a1fa600c59"
      },
      "cell_type": "code",
      "source": [
        "print(int_to_char)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: ' ', 2: 'e', 3: 't', 4: 'a', 5: 'o', 6: 'n', 7: 'i', 8: 'h', 9: 'r', 10: 's', 11: 'd', 12: 'l', 13: 'u', 14: '\\n', 15: 'm', 16: 'c', 17: 'y', 18: 'f', 19: 'w', 20: 'g', 21: ',', 22: 'p', 23: 'b', 24: '.', 25: 'v', 26: 'k', 27: 'I', 28: '“', 29: '”', 30: 'M', 31: ';', 32: '-', 33: 'B', 34: 'z', 35: 'T', 36: 'x', 37: 'E', 38: '_', 39: 'L', 40: \"'\", 41: 'H', 42: 'C', 43: 'W', 44: 'j', 45: 'q', 46: 'D', 47: 'S', 48: 'A', 49: '!', 50: '?', 51: 'Y', 52: 'J', 53: 'P', 54: 'N', 55: 'G', 56: 'O', 57: 'F', 58: 'R', 59: ':', 60: 'K', 61: '1', 62: 'U', 63: '*', 64: '(', 65: ')', 66: '2', 67: '3', 68: '4', 69: '0', 70: 'V', 71: '5', 72: '/', 73: '8', 74: '6', 75: '9', 76: '7', 77: 'Z', 78: 'X', 79: '@', 80: '$', 81: '\\ufeff', 82: '[', 83: '#', 84: ']', 85: '%', 86: 'Q'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WwevjLCRCxtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a89d435-b57f-4f48-f4bd-f61019569c8f"
      },
      "cell_type": "code",
      "source": [
        "current_seq = np.copy(test_seq)\n",
        "current_seq.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "WN480dgMYdBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_seq(epoch, logs):\n",
        "    \n",
        "    print('Output sequence is: ')\n",
        "    \n",
        "    #Initialize predicted output\n",
        "    predicted_output = ''\n",
        "    \n",
        "    #lets predict 50 next chars\n",
        "    current_seq = np.copy(test_seq)\n",
        "    for i in range(50):\n",
        "        data_input = np.reshape(current_seq,(1,                                  # We'll use one input\n",
        "                                             current_seq.shape[0],               # each input has length of 100 chars\n",
        "                                             current_seq.shape[1]))              # each char is represented by one number\n",
        "        \n",
        "        #Get the char int with maximum probability\n",
        "        predicted_char_int = np.argmax(model.predict(data_input)[0])\n",
        "        \n",
        "        #Add to the predicted out, convert int to char\n",
        "        predicted_output = predicted_output + int_to_char[predicted_char_int]\n",
        "        \n",
        "        #Update seq with new value at the end\n",
        "        current_seq = np.roll(current_seq, -1)\n",
        "        current_seq[current_seq.shape[0]-1] = [predicted_char_int/vocab_size]\n",
        "    \n",
        "    print(predicted_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QgAvC0axC_wU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6484c4b6-b0e2-42ce-d182-2e7e904b2400"
      },
      "cell_type": "code",
      "source": [
        "data_input=np.reshape(current_seq,(1,current_seq.shape[0],current_seq.shape[1]))\n",
        "data_input.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "6SenSd01R88X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Prediction"
      ]
    },
    {
      "metadata": {
        "id": "kEciXNf_BXNx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.callbacks import LambdaCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDUs4OlmYdGY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = LambdaCallback(on_epoch_end=predict_seq)                            # Create a LabdaCallback to do prediction at end of every epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5vFnVihYdJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b8d1f0a-ec18-44dc-a30a-a1ab5c09230e"
      },
      "cell_type": "code",
      "source": [
        "#Print random starting sequence for prediction\n",
        "print('Initial sequence is: ')\n",
        "for i in range (sequence_length):\n",
        "    print(int_to_char[int(test_seq[i]*vocab_size)], end='')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial sequence is: \n",
            "ton has our directions,\n",
            "and all will pe completed in a week. They will then join his regiment,\n",
            "unles"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YwKbw4JdYdLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "832303c0-affc-43b3-a720-da1b9bfafffb"
      },
      "cell_type": "code",
      "source": [
        "model.fit(input_data, output_data, \n",
        "          batch_size=128, \n",
        "          epochs=1,\n",
        "          callbacks=[checkpoint])                                               #As epoch increases model produces more correct output. In this case we've shown 1 epoch "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "704090/704090 [==============================] - 4005s 6ms/step - loss: 2.9451\n",
            "Output sequence is: \n",
            "  ho  he  he  he  he  he  he  he  he  he  he  he  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc3e629b7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "osiTcqsdYdO1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Z9SDHeAYdR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLDJOtbuYdV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhwxVWY0YdUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFciauh3YdEp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}